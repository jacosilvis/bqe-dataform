config {
  type: "operations",
  schema: dataform.projectConfig.vars.TARGET_DATA,
  name: "collect_jobs_timeline",
  hasOutput: false,
  tags: ["COLLECT_JOBS_TIMELINE"],
}


CREATE TEMPORARY TABLE jobs_timeline_${ dataform.projectConfig.vars.PRIMARY_REGION } AS
SELECT
    "${ dataform.projectConfig.vars.PRIMARY_REGION }" as bq_region
  , project_id
  , period_start
  , job_id
  , period_slot_ms
  , IF(state = 'DONE', total_bytes_processed, 0) AS total_bytes_processed
  , IF(state = 'DONE', total_bytes_billed, 0) AS total_bytes_billed
  , job_type
  , statement_type
  , job_creation_time
  , job_start_time
  , job_end_time
  , state AS job_state
  , reservation_id
FROM `region-${ dataform.projectConfig.vars.PRIMARY_REGION }.INFORMATION_SCHEMA.JOBS_TIMELINE_BY_ORGANIZATION`
WHERE job_creation_time >= "${ dataform.projectConfig.vars.START_DATE }"
  AND period_start >= "${ dataform.projectConfig.vars.START_DATE }"

  -- Avoid duplicate byte counting in parent and children jobs.
  AND (statement_type != "SCRIPT" OR statement_type IS NULL)

  -- Only Valid Reservations or On-Demand Slot Usage
  AND (   (reservation_id IS NULL AND job_type = "QUERY")
       OR (reservation_id IS NOT NULL AND reservation_id != "default-pipeline"))

-- Ignore any jobs which have zero slot usage
QUALIFY SUM(period_slot_ms) OVER (PARTITION BY bq_region, project_id, job_id) > 0
;


EXPORT DATA
OPTIONS (
  format = "CSV",
  field_delimiter = "\t",
  header = true,
  overwrite = true,
  uri = "gs://${ dataform.projectConfig.vars.EXPORT_GCS_BUCKET }/jobs_timeline/${ dataform.projectConfig.vars.PRIMARY_REGION }_*.csv"
) AS
SELECT
  *
FROM jobs_timeline_${ dataform.projectConfig.vars.PRIMARY_REGION }
;
